{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpRNh1-L8zuk"
      },
      "source": [
        "## Assessment / Midterm: Machine Vision and Deep Learning\n",
        "<span style=\"color:blue\">\n",
        "    \n",
        "1) Answer all questions\n",
        "    \n",
        "2) This assessment is open-book. You are allowed to refer to any references including online materials, books, notes, codes, github links, etc\n",
        "\n",
        "3) Copy this notebook to your google drive (click **FILE** > **save a copy in Drive**)\n",
        "\n",
        "4) Upload the answer notebook & trained model (for Question 3) to your github. \n",
        "\n",
        "5) Submit the assessment by sharing the link to your github containing the answers. \n",
        "    \n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo-GfeGJudmM"
      },
      "source": [
        "**QUESTION 1 [15 marks]**\n",
        "\n",
        "a) Let *k*, *s* and *p* be 4, 2 and 1, respectively. What will be the shape of the output of the convolutional layer? (2 marks)\n",
        "\n",
        ">>import torch \\\n",
        "import torch.nn as nn \\\n",
        "input_img = torch.rand(1,3,10,10) \\\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=*k*, stride=*s*, padding=*p*)\n",
        "\n",
        "<span style=\"color:blue\">\n",
        "    answer: The shape of the output of the convolutional layer will be (1, 12, 5, 5). The dimensions of the output are estimated as follows:In this situation, the number of output channels equals the number of out channels, which is 12. The output's spatial dimensions are computed as follows: (input size - kernel size + 2 * padding) / stride + 1. In this instance, the result is (5 = (10 - 4 + 2 * 1) / 2 + 1) Thus, the output tensor will have the shape (1, 12, 5, 5).\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7IbRrCXudmN"
      },
      "source": [
        "b) Batch Normalization (BN) normalizes the mean and standard deviation for each: (tick X for the correct answer) (2 marks)\n",
        "\n",
        " - [x] Individual feature map\n",
        " - [ ] Instance in the mini-batch\n",
        " - [ ] Spatial dimension    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbw5UFJIudmO"
      },
      "source": [
        "c) Which one of the following is not an advantage of Batch Normalization (BN)? (tick X for the correct answer) (2 marks)\n",
        "\n",
        "- [ ] BN accelerates the training of deep neural networks and tackles the vanishing gradient problem.\n",
        "- [ ] For every input mini-batch, we calculate different statistics. This introduces some sort of regularization.\n",
        "- [ ] BN reduces the dependence of gradients on the scale of the parameters or of their initial values.\n",
        "- [x] BN needs a much slower learning rate for the total architecture to converge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnM-cw3EudmO"
      },
      "source": [
        "d) Choose the correct statement. (tick X for the correct answer) (2 marks)\n",
        "\n",
        "- [x] A larger kernel is preferred for information that resides globally, and a smaller kernel is preferred for information that is distributed locally.\n",
        "- [ ] A larger kernel is preferred for information that resides locally, and a smaller kernel is preferred for information that is distributed globally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHiZ59IIudmO"
      },
      "source": [
        "e) In the following network, how many learnable parameters (weights) are there? (2 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Apz6i64vudmP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f05518a4-868a-4765-e6cd-a191a3a1b5cd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1bc2f0122bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = nn.Sequential(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "        nn.Linear(3,20),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(20,2)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ9yVaZMudmQ"
      },
      "source": [
        "<span style=\"color:blue\">\n",
        "    answer: there are 120 learnable parameteres \n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXF99wNfudmR"
      },
      "source": [
        "f) Which of the following statements are true about deep neural networks? (tick X for the correct answer) (2 marks)\n",
        "\n",
        "- [x] Deep neural networks usually require a big amount of data to be properly trained.\n",
        "- [x] They can be fooled by adversarial/ noisy examples.\n",
        "- [x] They are difficult to interpret and understand.\n",
        "- [x] They can still be subject to biases.\n",
        "- [x] They fail to understand the context of the data that they are handling.\n",
        "- [ ] They perform very well on individual tasks but fail to generalize to many different tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvRsowSfudmR"
      },
      "source": [
        "g) Run the code in the next cell. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKZRHMERudmS"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "from sklearn.datasets import make_moons\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# generate synthetic data in 2D\n",
        "X, Y = make_moons(500, noise=0.2)\n",
        "\n",
        "# plot the data\n",
        "plt.scatter(X[:,0], X[:,1], c=Y)\n",
        "plt.title('2D Data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpMVmMoNudmS"
      },
      "source": [
        "Can this data be correctly separable using the classifier below? Why? (3 marks)\n",
        "\n",
        "model = nn.Sequential( \\\n",
        "    nn.Linear(n_input_dim, n_output), \\\n",
        "    nn.Sigmoid() \\\n",
        "    )\n",
        "    \n",
        "<span style=\"color:blue\">\n",
        "    answer: Without further information, the provided classifier cannot correctly separate the data. Depending on the complexity of the data and the values of the model's hyperparameters, the classifier you have provided may or may not be adequate to effectively model the data. It is a straightforward linear model with a single hidden layer. We would need to train the model on the data and assess its performance in order to establish whether the data can be accurately separated using this classifier.\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjRauIpz8zun"
      },
      "source": [
        "**QUESTION 2 [50 marks]** \n",
        "\n",
        "The COVID-19 pandemic continues to have a devastating effect on the health and well-being of the global population. A critical step in the fight against COVID-19 is effective screening of infected patients, with one of the key screening approaches being radiology examination using chest radiography. As a deep learning engineer, you are tasked to classify a dataset of X-ray images as either \"normal\", \"covid\" or \"viral pneumonia\". Use the chest X-ray dataset publicly available at https://www.kaggle.com/datasets/pranavraikokte/covid19-image-dataset to answer the following questions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzzvkxpn8zuo"
      },
      "source": [
        "a) Train a feedforward neural network to solve the classification problem. Please include: **(10 marks)**\n",
        "\n",
        "    1) The dataloader to load the train and test datasets.\n",
        "\n",
        "    2) The model definition (either using sequential method OR pytorch class method).\n",
        "\n",
        "    3) The training loop.\n",
        "\n",
        "    4) Output the mean accuracy for the whole testing dataset.\n",
        "    \n",
        "    5) The hyperparameters are:\n",
        "        i  - architecture: 2 hidden layers\n",
        "        ii - input size  : 32x32 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0hERYSq8zuo"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "###############YOUR CODES HERE ################\n",
        "###############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW6A4Pmj8zuo"
      },
      "source": [
        "b) Create and train a ConvNet corresponding to the following architecture in Fig. 1 (with modifications of the input and final layers). Please include **(10 marks)**:\n",
        "\n",
        "    1) The dataloader to load the train and test datasets.\n",
        "\n",
        "    2) The model definition (either using sequential method OR pytorch class method).\n",
        "\n",
        "    3) Define your training loop.\n",
        "\n",
        "    4) Output the mean accuracy for the whole testing dataset.\n",
        "\n",
        "![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/LeNet.png)\n",
        "    \n",
        "                                Fig. 1: A convolutional neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ue0OHCL8zup"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "###############YOUR CODES HERE ################\n",
        "###############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MvkvKWHudmT"
      },
      "source": [
        "c) Based on Question 2 b), answer the following questions: \n",
        "    \n",
        "    i) Is the model overfitting? Why? (4 marks)\n",
        "   <font color='blue'> the model has overfitting issues becasue it has been trained with a lot of data </font>\n",
        "    \n",
        "    ii) Propose two methods to reduce the effect of overfitting. (4 marks)\n",
        "   <font color='blue'>Two methods that I propose are: (1) patch normalization (2) increase number of epoch </font>\n",
        "   \n",
        "    iii) Implement the two proposed methods in Q2 c) ii) in the next cell and show that the overfitting has been reduced. (8 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkNJQuUOudmU"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "###############YOUR CODES HERE ################\n",
        "###############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Zjsjxq8zuq"
      },
      "source": [
        "d) Replace your defined ConvNet in b) with a pre-trained model. Then, proceed with a transfer learning and finetune the model for the COVID-19 dataset. **(10 marks)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4joDd5u8zur"
      },
      "outputs": [],
      "source": [
        "###############################################\n",
        "###############YOUR CODES HERE ################\n",
        "###############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzPPxsCX8zus"
      },
      "source": [
        "e) Do you see any accuracy improvement? Whether it is a \"yes\" or \"no\", discuss the possible reasons contributing to the accuracy improvement/ unimprovement. **(4 marks)**\n",
        "\n",
        "<span style=\"color:blue\">\n",
        "    A model that has a head start in knowing which parameters are likely to achieve good results can be optimized faster compared to starting from scratch. Furthermore, pre-trained models have the benefit of not needing as much data as building a model from scratch.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCy3b5888zut"
      },
      "source": [
        "**QUESTION 3** **[15 marks]**\n",
        "\n",
        "In a machine vision project, you decide to design a door access control system based on hand gestures. Only those who shows the correct hand gesture will be granted the access. There are three gestures that are recognized as correct access passcode which are \"shaka\", \"peace\" and \"thumbs up\", as depicted in Fig. 2.\n",
        "\n",
        "![pic](https://simplyorganizedhi.com/media/catalog/product/1/6/169500.jpg)\n",
        "\n",
        "                                Fig. 2 Shaka,peace, and thumbs up\n",
        "\n",
        "\n",
        "Using the end-to-end object detection pipeline that you have learned, develop your own hand gesture detector so that it can be incorporate to a door access control system.\n",
        "\n",
        "Deliverables for this question are:\n",
        "\n",
        "- the model file. Change the name to <your_name>.pt file (e.g. hasan.pt).\n",
        "\n",
        "- 5 marks for plausible detection of each gesture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oIfLdzS8zut"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch_hasan",
      "language": "python",
      "name": "pytorch_hasan"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}